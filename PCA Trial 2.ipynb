{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "import numpy\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "from resizeimage import resizeimage\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import sparse\n",
    "from sklearn.decomposition import PCA\n",
    "import copy\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.decomposition import RandomizedPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "# resize images\n",
    "def resizeImagesToDest(source, dest, prefix, height, noiseAlgo=None):    \n",
    "    for root, dirs, files in os.walk(source):\n",
    "        for name in files:\n",
    "            if re.match(r'^'+prefix+'.*gif$', name, re.I):\n",
    "                img = Image.open(os.path.join(source, name))\n",
    "                (origWidth, origHeight) = img.size\n",
    "                if (height == origHeight):\n",
    "                    resizedImg = img\n",
    "                else:\n",
    "                    resizedImg = resizeimage.resize_height(img, height)\n",
    "                \n",
    "                (width, height) = resizedImg.size\n",
    "                if noiseAlgo:\n",
    "                    noisyImg = noiseAlgo(numpy.asarray(resizedImg))\n",
    "                    Image.fromarray(numpy.uint8(noisyImg.reshape(height,width))).save(dest+name)\n",
    "                else:\n",
    "                    resizedImg.save(dest+name)\n",
    "\n",
    "def resizeImages(source, prefix):\n",
    "    resizeImagesToDest(source, 'yalefaces_resized/', prefix, 50)\n",
    "                \n",
    "# images into array: http://stackoverflow.com/questions/13550376/pil-image-to-array-numpy-array-to-array-python\n",
    "def readImagesIntoMatrix(path, prefix):\n",
    "    images = None\n",
    "    groups = collections.defaultdict(set)\n",
    "    grouptag = {}\n",
    "    i = 0\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for name in files:\n",
    "            if re.match(r'^'+prefix+'.*gif$', name, re.I):\n",
    "                img = Image.open(path + name)                \n",
    "                (width, height) = img.size\n",
    "                imgArr = numpy.asarray(img).reshape(height * width)\n",
    "                if images is not None:\n",
    "                    images = numpy.vstack([images, imgArr])\n",
    "                else:\n",
    "                    images = imgArr\n",
    "                group = re.match(r'.*yaleB([0-9]+)_.*', name, re.I).group(1)\n",
    "                groups[group].add(i)\n",
    "                grouptag[i] = group\n",
    "                i += 1\n",
    "    return images, groups, grouptag\n",
    "\n",
    "def saveImages(path, images, width, height):\n",
    "    for i in range(0, len(images)):\n",
    "        Image.fromarray(numpy.uint8(images[i]).reshape(height, width)).save(path+str(i)+'.gif')\n",
    "        \n",
    "def addGaussianNoise(image):\n",
    "    noisyImage = copy.deepcopy(image)\n",
    "    mu = noisyImage.mean()\n",
    "    std = noisyImage.std()\n",
    "    noise = 0.2 * numpy.random.normal(mu, std, noisyImage.shape)\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[0])):\n",
    "            val = image[i][j]\n",
    "            if val + noise[i][j] >= 255:\n",
    "                noisyImage[i][j] = 255\n",
    "            elif val + noise[i][j] <= 0:\n",
    "                noisyImage[i][j] = 0\n",
    "            else:\n",
    "                noisyImage[i][j] = val + noise[i][j] \n",
    "    \n",
    "    return noisyImage  \n",
    "    \n",
    "def addSparseNoise(image):\n",
    "    noisyImage = copy.deepcopy(image)\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image[0])):\n",
    "            rand = random.random()\n",
    "            if (rand <= 0.01):\n",
    "                noisyImage[i][j] = 0\n",
    "    \n",
    "    return noisyImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images [[ 72   6  55 ...,  51 127  39]\n",
      " [ 73   7  59 ...,  58 130  38]\n",
      " [ 75   8  65 ...,  59 132  41]\n",
      " ..., \n",
      " [ 34 128  60 ...,  20  15  46]\n",
      " [ 33 132  55 ...,  16  15  39]\n",
      " [ 31 129  48 ...,  12  17  32]]\n"
     ]
    }
   ],
   "source": [
    "imageList, groups, grouptag = readImagesIntoMatrix('brightyalefaces/', '.*')\n",
    "imageList = imageList.T\n",
    "\n",
    "print(\"Images %s\" % imageList)\n",
    "\n",
    "(width, height) = 168, 192\n",
    "Image.fromarray(numpy.uint8(imageList.T[0].reshape(height,width))).save(\"secondyaletest/testsaveimage1.gif\")\n",
    "Image.fromarray(numpy.uint8(imageList.T[100].reshape(height,width))).save(\"secondyaletest/testsaveimage100.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average image [ 57.21857923  59.01457195  61.05919854 ...,  41.61020036  40.18397086\n",
      "  39.16484517]\n"
     ]
    }
   ],
   "source": [
    "# average Image\n",
    "#print('Num images %s' % (imageList.shape,))\n",
    "avgImg = imageList.mean(axis=1)\n",
    "print('Average image %s' % (avgImg))\n",
    "normalizedImageList = imageList - avgImg.reshape(width*height,1)*numpy.ones((1,len(imageList.T)))\n",
    "Image.fromarray(numpy.uint8(avgImg.reshape(height,width))).save('secondyaletest/avgImg.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With PCA there were 42 eigenfaces that captures 90pct of the variance\n"
     ]
    }
   ],
   "source": [
    "def normalize_face(vector):\n",
    "    minValue = numpy.amin(vector)\n",
    "    maxValue = numpy.amax(vector)\n",
    "    scale = (255./(maxValue-minValue))\n",
    "    return (vector - minValue)*scale\n",
    "\n",
    "# Fit with PCA for 90% of variance\n",
    "pca = PCA(0.9).fit_transform(normalizedImageList)\n",
    "print('With PCA there were %s eigenfaces that captures 90pct of the variance' % len(pca.T))\n",
    "\n",
    "for i in range(len(pca.T)):\n",
    "    eigv = pca[:,i].reshape(1,width * height).T\n",
    "    eigenface = normalize_face(eigv)\n",
    "    Image.fromarray(numpy.uint8(eigenface.reshape(height,width))).save('secondyaletest/trial2-eigenface%s.gif' % i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy.linalg import norm, svd\n",
    "from scipy.io import loadmat, savemat\n",
    "\n",
    "def inexact_augmented_lagrange_multiplier(X, lmbda=.01, tol=1e-3,\n",
    "                                          maxiter=100, verbose=True):\n",
    "    \"\"\"\n",
    "    Inexact Augmented Lagrange Multiplier\n",
    "    \"\"\"\n",
    "    Y = X\n",
    "    norm_two = norm(Y.ravel(), 2)\n",
    "    norm_inf = norm(Y.ravel(), numpy.inf) / lmbda\n",
    "    dual_norm = numpy.max([norm_two, norm_inf])\n",
    "    Y = Y / dual_norm\n",
    "    A = numpy.zeros(Y.shape)\n",
    "    E = numpy.zeros(Y.shape)\n",
    "    dnorm = norm(X, 'fro')\n",
    "    mu = 1.25 / norm_two\n",
    "    rho = 1.5\n",
    "    sv = 10.\n",
    "    n = Y.shape[0]\n",
    "    itr = 0\n",
    "    while True:\n",
    "        if verbose:\n",
    "            print('Iterations %s' % itr)\n",
    "        Eraw = X - A + (1 / mu) * Y\n",
    "        Eupdate = numpy.maximum(Eraw - lmbda / mu, 0) + numpy.minimum(Eraw + lmbda / mu, 0)\n",
    "        U, S, V = svd(X - Eupdate + (1 / mu) * Y, full_matrices=False)\n",
    "        svp = (S > 1 / mu).shape[0]\n",
    "        if svp < sv:\n",
    "            sv = numpy.min([svp + 1, n])\n",
    "        else:\n",
    "            sv = numpy.min([svp + round(.05 * n), n])\n",
    "        Aupdate = numpy.dot(numpy.dot(U[:, :svp], numpy.diag(S[:svp] - 1 / mu)), V[:svp, :])\n",
    "        A = Aupdate\n",
    "        E = Eupdate\n",
    "        Z = X - A - E\n",
    "        Y = Y + mu * Z\n",
    "        mu = numpy.min([mu * rho, mu * 1e7])\n",
    "        itr += 1\n",
    "        if ((norm(Z, 'fro') / dnorm) < tol) or (itr >= maxiter):\n",
    "            break\n",
    "    if verbose:\n",
    "        print(\"Finished at iteration %d\" % (itr))  \n",
    "    return A,E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 0\n",
      "Iterations 1\n",
      "Iterations 2\n",
      "Iterations 3\n",
      "Iterations 4\n",
      "Iterations 5\n",
      "Iterations 6\n",
      "Iterations 7\n",
      "Iterations 8\n",
      "Iterations 9\n",
      "Iterations 10\n",
      "Iterations 11\n",
      "Iterations 12\n",
      "Iterations 13\n",
      "Iterations 14\n",
      "Iterations 15\n",
      "Iterations 16\n",
      "Iterations 17\n",
      "Iterations 18\n",
      "Finished at iteration 19\n"
     ]
    }
   ],
   "source": [
    "A, E = inexact_augmented_lagrange_multiplier(normalizedImageList, lmbda=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterations 0\n",
      "Iterations 1\n",
      "Iterations 2\n",
      "Iterations 3\n",
      "Iterations 4\n",
      "Iterations 5\n",
      "Iterations 6\n",
      "Iterations 7\n",
      "Iterations 8\n",
      "Iterations 9\n",
      "Iterations 10\n",
      "Iterations 11\n",
      "Iterations 12\n",
      "Iterations 13\n",
      "Iterations 14\n",
      "Iterations 15\n",
      "Iterations 16\n",
      "Iterations 17\n",
      "Iterations 18\n",
      "Iterations 19\n",
      "Iterations 20\n",
      "Iterations 21\n",
      "Iterations 22\n",
      "Iterations 23\n",
      "Iterations 24\n",
      "Iterations 25\n",
      "Iterations 26\n",
      "Finished at iteration 27\n"
     ]
    }
   ],
   "source": [
    "A2, E2 = inexact_augmented_lagrange_multiplier(normalizedImageList, lmbda=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A3, E3 = inexact_augmented_lagrange_multiplier(normalizedImageList, lmbda=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A4, E4 = inexact_augmented_lagrange_multiplier(normalizedImageList, lmbda=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image.fromarray(numpy.uint8((A.T[0] + avgImg).reshape(height,width))).save(\"secondyaletest/testsaveimage1afterrpca.gif\")\n",
    "\n",
    "print('Error %s' % E)\n",
    "print('Error %s' % E2)\n",
    "\n",
    "print('Relative error %s %s' % (0.01, numpy.linalg.norm(E, 'fro')/numpy.linalg.norm(normalizedImageList, 'fro')))\n",
    "print('Relative error %s %s' % (0.005, numpy.linalg.norm(E2, 'fro')/numpy.linalg.norm(normalizedImageList, 'fro')))\n",
    "print('Relative error %s %s' % (0.2, numpy.linalg.norm(E3, 'fro')/numpy.linalg.norm(normalizedImageList, 'fro')))\n",
    "print('Relative error %s %s' % (0.001, numpy.linalg.norm(E4, 'fro')/numpy.linalg.norm(normalizedImageList, 'fro')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Fit with PCA for 90% of variance\n",
    "rpca = PCA(0.9).fit_transform(A)\n",
    "rpca2 = PCA(0.9).fit_transform(A2)\n",
    "rpca4 = PCA(0.9).fit_transform(A4)\n",
    "\n",
    "print('After RPCA (lam=%s) there were %s eigenfaces that captures 90pct of the variance' % (0.01, len(rpca.T)))\n",
    "print('After RPCA (lam=%s) there were %s eigenfaces that captures 90pct of the variance' % (0.005, len(rpca2.T)))\n",
    "print('After RPCA (lam=%s) there were %s eigenfaces that captures 90pct of the variance' % (0.001, len(rpca4.T)))\n",
    "\n",
    "#Let's make images for the same number of eigenfaces we used originally\n",
    "rpca = PCA(len(pca.T)).fit_transform(A)\n",
    "rpca2 = PCA(len(pca.T)).fit_transform(A2)\n",
    "rpca3 = PCA(len(pca.T)).fit_transform(A3)\n",
    "rpca4 = PCA(len(pca.T)).fit_transform(A4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xdata = [0.0]*len(pca.T)\n",
    "ydata = [0.0]*len(pca.T)\n",
    "ydataRPCA = [0.0]*len(pca.T)\n",
    "ydataRPCA2 = [0.0]*len(pca.T)\n",
    "ydataRPCA3 = [0.0]*len(pca.T)\n",
    "ydataRPCA4 = [0.0]*len(pca.T)\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "pca_normalized = normalize(pca, axis=0, norm='l2')\n",
    "rpca_normalized = normalize(rpca, axis=0, norm='l2')\n",
    "rpca2_normalized = normalize(rpca2, axis=0, norm='l2')\n",
    "rpca3_normalized = normalize(rpca3, axis=0, norm='l2')\n",
    "rpca4_normalized = normalize(rpca4, axis=0, norm='l2')\n",
    "\n",
    "grouptagarray = [\"\"]*len(grouptag)\n",
    "for i in range(len(grouptag)):\n",
    "    grouptagarray[i] = grouptag[i]\n",
    "\n",
    "for metric in ['cityblock', 'cosine', 'euclidean']:\n",
    "    original_clustering = silhouette_score(normalizedImageList.T, grouptagarray, metric=metric)\n",
    "    print('In the original dimension silhouette is %s' % original_clustering)\n",
    "\n",
    "    for i in range(len(pca.T)):\n",
    "      xdata[i] = i\n",
    "      projected = normalizedImageList.T.dot(pca_normalized[:,:i+1])\n",
    "      ydata[i] = silhouette_score(projected, grouptagarray)\n",
    "    \n",
    "      # lambda = 0.01\n",
    "      projectedRPCA = normalizedImageList.T.dot(rpca_normalized[:,:i+1])\n",
    "      ydataRPCA[i] = silhouette_score(projectedRPCA, grouptagarray)\n",
    "    \n",
    "      # lambda = 0.005\n",
    "      projectedRPCA2 = normalizedImageList.T.dot(rpca2_normalized[:,:i+1])\n",
    "      ydataRPCA2[i] = silhouette_score(projectedRPCA2, grouptagarray)\n",
    "    \n",
    "      # lambda = 0.02\n",
    "      projectedRPCA3 = normalizedImageList.T.dot(rpca3_normalized[:,:i+1])\n",
    "      ydataRPCA3[i] = silhouette_score(projectedRPCA3, grouptagarray)\n",
    "    \n",
    "      # lambda = 0.001\n",
    "      projectedRPCA4 = normalizedImageList.T.dot(rpca4_normalized[:,:i+1])\n",
    "      ydataRPCA4[i] = silhouette_score(projectedRPCA4, grouptagarray)\n",
    "\n",
    "    print('Clustering silhouette over PCA %s' % ydata)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(\"Silhouette (%s) in PCA\" % metric)\n",
    "    plt.plot(xdata, ydata, label=\"PCA\")\n",
    "    plt.plot(xdata, ydataRPCA, label=\"RPCA (lambda = 0.01)\")\n",
    "    plt.plot(xdata, ydataRPCA2, label=\"RPCA (lambda = 0.005)\")\n",
    "    plt.plot(xdata, ydataRPCA3, label=\"RPCA (lambda = 0.02)\")\n",
    "    plt.plot(xdata, ydataRPCA4, label=\"RPCA (lambda = 0.001)\")\n",
    "    plt.axhline(y=original_clustering, color='r', linestyle='-', label='Original Score (without dimensional reduction)')\n",
    "    plt.xlabel(\"Num eigenvector used\")\n",
    "    plt.ylabel(\"Silhouette (%s)\" % metric)\n",
    "    plt.autoscale(enable=True, axis='x', tight=True)\n",
    "    plt.legend()\n",
    "    plt.savefig(\"figures/rpcatrial2%s.png\" % metric, format = 'png')\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imagesH = None\n",
    "rpcaImagesH = None\n",
    "rpcaImagesH2 = None\n",
    "rpcaImagesH3 = None\n",
    "\n",
    "count = 0\n",
    "for i in groups[\"24\"]:\n",
    "    if count > 5:\n",
    "        break\n",
    "    if imagesH is None:\n",
    "        imagesH = imageList.T[i].reshape(height,width)\n",
    "    else:\n",
    "        imagesH = numpy.hstack([imagesH, imageList.T[i].reshape(height,width)])\n",
    "    if rpcaImagesH is None:\n",
    "        rpcaImagesH = (A.T[i] + avgImg).reshape(height,width)\n",
    "    else:\n",
    "        rpcaImagesH = numpy.hstack([rpcaImagesH, (A.T[i] + avgImg).reshape(height,width)])\n",
    "    if rpcaImagesH2 is None:\n",
    "        rpcaImagesH2 = (A2.T[i] + avgImg).reshape(height,width)\n",
    "    else:\n",
    "        rpcaImagesH2 = numpy.hstack([rpcaImagesH2, (A2.T[i] + avgImg).reshape(height,width)])\n",
    "    if rpcaImagesH3 is None:\n",
    "        rpcaImagesH3 = (A4.T[i] + avgImg).reshape(height,width)\n",
    "    else:\n",
    "        rpcaImagesH3 = numpy.hstack([rpcaImagesH3, (A4.T[i] + avgImg).reshape(height,width)])\n",
    "    count += 1\n",
    "    \n",
    "def removeOutliers(array):\n",
    "    for i in range(len(array)):\n",
    "        for j in range(len(array[0])):\n",
    "            if array[i][j] > 255:\n",
    "                array[i][j] = 255\n",
    "            elif array[i][j] < 0:\n",
    "                array[i][j] = 0\n",
    "    return array\n",
    "    \n",
    "Image.fromarray(numpy.uint8(imagesH)).save(\"figures/person24trial2.gif\")\n",
    "Image.fromarray(numpy.uint8(removeOutliers(rpcaImagesH))).save(\"figures/person24Afterl=0dot01RPCAtrial2.gif\")\n",
    "Image.fromarray(numpy.uint8(removeOutliers(rpcaImagesH2))).save(\"figures/person24Afterl=0dot005RPCAtrial2.gif\")\n",
    "Image.fromarray(numpy.uint8(removeOutliers(rpcaImagesH3))).save(\"figures/person24Afterl=0dot001RPCAtrial2.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5\n",
      "10\n",
      "15\n",
      "20\n",
      "25\n",
      "30\n",
      "35\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "def AddH(images, toadd):\n",
    "    if images is None:\n",
    "        images = toadd\n",
    "    else:\n",
    "        images = numpy.hstack([images, toadd])\n",
    "    return images\n",
    "        \n",
    "def AddV(images, toadd):\n",
    "    if images is None:\n",
    "        images = toadd\n",
    "    else:\n",
    "        images = numpy.vstack([images, toadd])\n",
    "    return images\n",
    "        \n",
    "imagesV = None\n",
    "rpcaImagesV = None\n",
    "rpcaImagesV4 = None\n",
    "\n",
    "height, width = 192, 168\n",
    "    \n",
    "\n",
    "for k in range(0, len(pca.T), 5):\n",
    "    print(k)\n",
    "    rowImagesH = None\n",
    "    rowRpcaImagesH = None\n",
    "    rowRpcaImagesH4 = None\n",
    "    for j in range(0, 4):\n",
    "        i = j + k\n",
    "        if i < len(pca.T):\n",
    "            eigv = pca[:,i].reshape(1,width * height).T\n",
    "            eigenface = normalize_face(eigv).reshape(height, width)\n",
    "            rpcaeigv = rpca2[:,i].reshape(1,width * height).T\n",
    "            rpcaeigenface = normalize_face(rpcaeigv).reshape(height, width)\n",
    "            rpcaeigv4 = rpca4[:,i].reshape(1,width * height).T\n",
    "            rpcaeigenface4 = normalize_face(rpcaeigv4).reshape(height, width)\n",
    "        else:\n",
    "            eigenface = 255*numpy.ones((height, width))\n",
    "            rpcaeigenface = 255*numpy.ones((height, width))\n",
    "            rpcaeigenface4 = 255*numpy.ones((height, width))\n",
    "        rowImagesH = AddH(rowImagesH, eigenface)\n",
    "        rowRpcaImagesH = AddH(rowRpcaImagesH, rpcaeigenface)\n",
    "        rowRpcaImagesH4 = AddH(rowRpcaImagesH4, rpcaeigenface4)\n",
    "    imagesV = AddV(imagesV, rowImagesH)\n",
    "    rpcaImagesV = AddV(rpcaImagesV, rowRpcaImagesH)\n",
    "    rpcaImagesV4 = AddV(rpcaImagesV4, rowRpcaImagesH4)\n",
    "        \n",
    "Image.fromarray(numpy.uint8(imagesV)).save(\"figures/trial2eigenfaces.gif\")\n",
    "Image.fromarray(numpy.uint8(rpcaImagesV)).save(\"figures/trial2rpca0dot005eigenfaces.gif\")\n",
    "Image.fromarray(numpy.uint8(rpcaImagesV4)).save(\"figures/trial2rpca0dot001eigenfaces.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
